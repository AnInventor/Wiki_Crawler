# Wiki_Crawler
Wiki Crawler will crawl through wikipedia pages and return edge list. Vertex are the web pages and edges are the links between the webpages.

Wiki_crawl.py will collect the wikipedia interlinks and returns the edge list which later can be build as graph. The output file will be in . csv format.


Steps to run the wiki_crawl.py file
>run the file 
>Enter the URL with http or https
>Enter the number of level need to be captured. 
>after completing execution the .csv file will be produced


